---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a second-year master's student at Xidian University, advised by Prof. De Cheng and Prof. Nannan Wang. Prior to this, I received my bachelor degree in Aerospace Science and Technology in 2023. My research interests are in computer vision and multi-modal learning, with specific interest in person re-identification, continual learning, parameter-efficient fine-tuning, unsupervised and semi-supervised learning, noisy label learning, etc.

[Email: lfhe@stu.xidian.edu.cn](lfhe@stu.xidian.edu.cn) / [Github](https://github.com/FranklinLingfeng) / [Google scholar](https://scholar.google.com/citations?user=bUCPpbAAAAAJ&hl=zh-CN)

---
permalink: /
title: "Publications (*equal contribution; only papers as first authors are included; double click to view abstract)"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

### Efficient bilateral cross-modality cluster matching for unsupervised visible-infrared person reid

De Cheng*, Lingfeng He*, Nannan Wang, Shizhou Zhang, Zhen Wang, Xinbo Gao
*Proceedings of the 31st ACM international conference on multimedia (ACM MM), 2023 (CCF-A, Oral)*
[[PDF]](your_pdf_link.pdf) [[Arxiv]]([your_bibtex_link.bib](https://arxiv.org/pdf/2305.12673))

<div style="display: flex; align-items: flex-start; margin-top: 10px;">
  <img src="/assets/images/PMAN_diagram.png" alt="PMAN Network" width="300" style="margin-right: 20px;">
  <p>
    Text-based person search aims to retrieve the target person in an image gallery based on textual descriptions.  
    We propose a Part-based Multi-Scale Attention Network (PMAN), which extracts visual semantic features at different scales and aligns them with textual features using ResNet, BERT, and Bottleneck Transformer.  
    Our method achieves state-of-the-art performance on the CUHK-PEDES dataset.
  </p>
</div>



